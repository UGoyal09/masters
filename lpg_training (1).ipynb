{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbryPNfKTiuO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import style\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV,\n",
        "                                     cross_val_score, train_test_split)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "# import category_encoders as ce\n",
        "import time\n",
        "import warnings\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4Gl5bHqVY_E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UULmE1eV3NP"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"lpg_training_data.csv\", skiprows=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIKTrUmuV8KR"
      },
      "outputs": [],
      "source": [
        "df.arrival_port.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hIS96V9WAbZ"
      },
      "outputs": [],
      "source": [
        "df.sub_segment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BounDu9nWCqK"
      },
      "outputs": [],
      "source": [
        "df.departure_port.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YqXhd6AWE2d"
      },
      "outputs": [],
      "source": [
        "df.sspd_mstd.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wJM8e_nWMkj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df).set_title('Distribution of Arrival Ports')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H46c1M1jWO0T"
      },
      "outputs": [],
      "source": [
        "df.groupby(['departure_port','arrival_port']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO4P_jtlWRlK"
      },
      "outputs": [],
      "source": [
        "df.groupby(['departure_port','arrival_port']).size().sort_values(ascending=False)[:9000].sum()/len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g44oE6XnWVb4"
      },
      "outputs": [],
      "source": [
        "df.groupby(['departure_port','arrival_port']).size().sort_values(ascending=False)[:9000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMX777iCWXvR"
      },
      "outputs": [],
      "source": [
        "df2 = df.groupby(['departure_port','arrival_port']).filter(lambda x: len(x) > 4)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjdnmTzoWYWm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df2).set_title('Distribution of Arrival Ports')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pScSnwlVWaNG"
      },
      "outputs": [],
      "source": [
        "df2.arrival_port.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGZzm-e2WcUA"
      },
      "outputs": [],
      "source": [
        "df2.arrival_port.value_counts()[:400].values.sum()/len(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PQy14m4WfzN"
      },
      "outputs": [],
      "source": [
        "df2.arrival_port.value_counts()[:400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUnaaANLWgSg"
      },
      "outputs": [],
      "source": [
        "removals = df2['arrival_port'].value_counts().reset_index()\n",
        "removals = removals[removals['arrival_port'] > 75]['index'].values\n",
        "removals.size\n",
        "df3 = df2[df2['arrival_port'].isin(removals)]\n",
        "df3.arrival_port.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRbyLk8DWicj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df3).set_title('Distribution of Arrival Ports')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n9sYqoYXpIt"
      },
      "outputs": [],
      "source": [
        "df3.to_csv(r'lpg_trained_data.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXgfoRDXWmNB"
      },
      "outputs": [],
      "source": [
        "X=df3.drop('arrival_port',axis=1).copy()\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3LkNpLCWpcJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "X.drop(['voyage_id', 'imo','mstd_id'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM6NUUlvWrdj"
      },
      "outputs": [],
      "source": [
        "y = df3['arrival_port'].copy()\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u5FLUUSWuH0"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded= le.fit(y)\n",
        "filehandler = open(\"enc_targets.obj\",\"wb\")\n",
        "pickle.dump(y_encoded,filehandler)\n",
        "filehandler.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX1VDfBbWyAN"
      },
      "outputs": [],
      "source": [
        "y_changed = y_encoded.transform(y)\n",
        "y_changed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S0Gq021W5bY"
      },
      "outputs": [],
      "source": [
        "dp = LabelEncoder()\n",
        "dp_enc = dp.fit(X['departure_port'])\n",
        "filehandler = open(\"dp_enc.obj\",\"wb\")\n",
        "pickle.dump(dp_enc,filehandler)\n",
        "filehandler.close()\n",
        "#########\n",
        "sea = LabelEncoder()\n",
        "sea_enc = sea.fit(X['season'])\n",
        "filehandler = open(\"sea_enc.obj\",\"wb\")\n",
        "pickle.dump(sea_enc,filehandler)\n",
        "filehandler.close()\n",
        "###########\n",
        "seg = LabelEncoder()\n",
        "seg_enc = seg.fit(X['sub_segment'])\n",
        "filehandler = open(\"seg_enc.obj\",\"wb\")\n",
        "pickle.dump(seg_enc,filehandler)\n",
        "filehandler.close()\n",
        "###############\n",
        "sspd = LabelEncoder()\n",
        "sspd_enc = sspd.fit(X['sspd_mstd'])\n",
        "filehandler = open(\"sspd_enc.obj\",\"wb\")\n",
        "pickle.dump(sspd_enc,filehandler)\n",
        "filehandler.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYTJv8ytW_aL"
      },
      "outputs": [],
      "source": [
        "file = open(\"dp_enc.obj\",'rb')\n",
        "dp_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"departure_port\"] = dp_enc.transform(X[\"departure_port\"])\n",
        "############\n",
        "file = open(\"sea_enc.obj\",'rb')\n",
        "sea_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"season\"] = sea_enc.transform(X[\"season\"])\n",
        "##############\n",
        "file = open(\"seg_enc.obj\",'rb')\n",
        "seg_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"sub_segment\"] = seg_enc.transform(X[\"sub_segment\"])\n",
        "#######################\n",
        "file = open(\"sspd_enc.obj\",'rb')\n",
        "sspd_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"sspd_mstd\"] = sspd_enc.transform(X[\"sspd_mstd\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Be8-YClXB8s"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw7MY-x3XEF5"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y_changed,test_size = 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4py-VuLXa5i"
      },
      "outputs": [],
      "source": [
        "clf = xgb.XGBClassifier(objective='multi:softmax',seed=42,learn_rate=0.1,max_depth=6,gamma=0.29,subsample=0.9)#colsample_bytree=0.5\n",
        "clf.fit(X_train,\n",
        "        y_train, \n",
        "        verbose=True,\n",
        "        eval_metric = ['merror','mlogloss'],\n",
        "        early_stopping_rounds=12,\n",
        "        eval_set=[(X_test,y_test),(X_train, y_train)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMOyyrRUXfbE"
      },
      "outputs": [],
      "source": [
        "clf.best_ntree_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9hhGuDZBegd"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(clf, open(\"lpg_model.dat\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNhqR7s7B0sQ"
      },
      "outputs": [],
      "source": [
        "def print_feature_importance(classifier,X):\n",
        "        # check Important features\n",
        "        feature_importances_df = pd.DataFrame(\n",
        "            {\"feature\": list(X.columns),\n",
        "             \"importance\": classifier.feature_importances_}\n",
        "        ).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "        # Display\n",
        "        print(\"\\n[XGBoostClassifier] feature importance:\")\n",
        "        print(feature_importances_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR5zr4SmB5Fg"
      },
      "outputs": [],
      "source": [
        "features = print_feature_importance(clf, X)\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrgjjPdmB6fW"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7duxR99wCJdF"
      },
      "outputs": [],
      "source": [
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions) \n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJhvU3SxHcMj"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "loaded_model = pickle.load(open(\"lpg_model.dat\", \"rb\"))\n",
        "results = loaded_model.evals_result()\n",
        "epochs = len(results['validation_0']['merror'])\n",
        "x_axis = range(0, epochs)\n",
        "from matplotlib import pyplot\n",
        "fig, ax = pyplot.subplots(figsize=(6,6))\n",
        "ax.plot(x_axis, results['validation_0']['mlogloss'], label='test')\n",
        "ax.plot(x_axis, results['validation_0']['merror'], label='train')\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoQiZ59dQloN"
      },
      "outputs": [],
      "source": [
        "from xgboost import plot_importance\n",
        "\n",
        "fig, ax = pyplot.subplots()\n",
        "plot_importance(loaded_model, ax=ax)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvcEp9AhR7cf"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "# import pickle\n",
        "# loaded_model = pickle.load(open(\"lpg_model.dat\", \"rb\"))\n",
        "results = clf.evals_result()\n",
        "pyplot.plot(results['validation_0']['mlogloss'], label='test')\n",
        "pyplot.plot(results['validation_1']['mlogloss'], label='train')\n",
        "pyplot.ylabel(\"Log Loss\")\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-Vs7hyWzwGT"
      },
      "outputs": [],
      "source": [
        "pyplot.plot(results['validation_0']['merror'], label='test')\n",
        "pyplot.plot(results['validation_1']['merror'], label='train')\n",
        "pyplot.ylabel(\"Classification Error\")\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iNssXI30FtN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lpg_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}