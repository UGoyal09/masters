{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chemical_training_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZaXlf_c5AT0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import style\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV,\n",
        "                                     cross_val_score, train_test_split)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "# import category_encoders as ce\n",
        "import time\n",
        "import warnings\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "n65Zk_C35cv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"dry_bulk_training_data.csv\", skiprows=0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Eotw4PpU5ghC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.arrival_port.value_counts()"
      ],
      "metadata": {
        "id": "7X2jXvYp5kWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sub_segment.value_counts()"
      ],
      "metadata": {
        "id": "BqWYcZmR51Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.departure_port.value_counts()"
      ],
      "metadata": {
        "id": "Y4mVsEMn5126"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sspd_mstd.value_counts()"
      ],
      "metadata": {
        "id": "d_e1_Iow53GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df).set_title('Distribution of Arrival Ports')"
      ],
      "metadata": {
        "id": "3gVGPOJY54bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['departure_port','arrival_port']).size()"
      ],
      "metadata": {
        "id": "SLSRGgzP56Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['departure_port','arrival_port']).size().sort_values(ascending=False)[:12000].sum()/len(df)"
      ],
      "metadata": {
        "id": "LoD7KUeC59Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['departure_port','arrival_port']).size().sort_values(ascending=False)[:9000]"
      ],
      "metadata": {
        "id": "GEAhvcMt5_Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.groupby(['departure_port','arrival_port']).filter(lambda x: len(x) > 4)\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "TmUacDeU6Ali"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df2).set_title('Distribution of Arrival Ports')"
      ],
      "metadata": {
        "id": "37UFu0rY6CxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.arrival_port.value_counts()"
      ],
      "metadata": {
        "id": "dgwVA9l_6EI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.arrival_port.value_counts()[:700].values.sum()/len(df2)"
      ],
      "metadata": {
        "id": "RiiaPegt6Fgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.arrival_port.value_counts()[:700]"
      ],
      "metadata": {
        "id": "FZLOngp-6HIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "removals = df2['arrival_port'].value_counts().reset_index()\n",
        "removals = removals[removals['arrival_port'] > 79]['index'].values\n",
        "removals.size\n",
        "df3 = df2[df2['arrival_port'].isin(removals)]\n",
        "df3.arrival_port.value_counts()\n"
      ],
      "metadata": {
        "id": "WwEwN8a86IrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df3).set_title('Distribution of Arrival Ports')"
      ],
      "metadata": {
        "id": "_PFiMZ6F6M8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.to_csv(r'dry_bulk_trained_data.csv', index = False)"
      ],
      "metadata": {
        "id": "eV2yZnK76PWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df3.drop('arrival_port',axis=1).copy()\n",
        "X.head()"
      ],
      "metadata": {
        "id": "APi83jkr6R8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X.drop(['voyage_id', 'imo','mstd_id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "z3bX9CBK6TVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df3['arrival_port'].copy()\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "5qF905P_6U9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded= le.fit(y)\n",
        "filehandler = open(\"enc_targets.obj\",\"wb\")\n",
        "pickle.dump(y_encoded,filehandler)\n",
        "filehandler.close()"
      ],
      "metadata": {
        "id": "Xca2_QgA6XBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_changed = y_encoded.transform(y)\n",
        "y_changed"
      ],
      "metadata": {
        "id": "0iUFJCz16ZQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dp = LabelEncoder()\n",
        "dp_enc = dp.fit(X['departure_port'])\n",
        "filehandler = open(\"dp_enc.obj\",\"wb\")\n",
        "pickle.dump(dp_enc,filehandler)\n",
        "filehandler.close()\n",
        "#########\n",
        "sea = LabelEncoder()\n",
        "sea_enc = sea.fit(X['season'])\n",
        "filehandler = open(\"sea_enc.obj\",\"wb\")\n",
        "pickle.dump(sea_enc,filehandler)\n",
        "filehandler.close()\n",
        "###########\n",
        "seg = LabelEncoder()\n",
        "seg_enc = seg.fit(X['sub_segment'])\n",
        "filehandler = open(\"seg_enc.obj\",\"wb\")\n",
        "pickle.dump(seg_enc,filehandler)\n",
        "filehandler.close()\n",
        "###############\n",
        "sspd = LabelEncoder()\n",
        "sspd_enc = sspd.fit(X['sspd_mstd'])\n",
        "filehandler = open(\"sspd_enc.obj\",\"wb\")\n",
        "pickle.dump(sspd_enc,filehandler)\n",
        "filehandler.close()"
      ],
      "metadata": {
        "id": "m9F7K6kA6dMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"dp_enc.obj\",'rb')\n",
        "dp_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"departure_port\"] = dp_enc.transform(X[\"departure_port\"])\n",
        "############\n",
        "file = open(\"sea_enc.obj\",'rb')\n",
        "sea_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"season\"] = sea_enc.transform(X[\"season\"])\n",
        "##############\n",
        "file = open(\"seg_enc.obj\",'rb')\n",
        "seg_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"sub_segment\"] = seg_enc.transform(X[\"sub_segment\"])\n",
        "#######################\n",
        "file = open(\"sspd_enc.obj\",'rb')\n",
        "sspd_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"sspd_mstd\"] = sspd_enc.transform(X[\"sspd_mstd\"])"
      ],
      "metadata": {
        "id": "4NDGY-DJ6nsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "wCno7pTh6pIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y_changed,test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TTdiuYm26q3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = xgb.XGBClassifier(objective='multi:softmax',seed=42,learn_rate=0.1,max_depth=6,gamma=0.29,subsample=0.9)#colsample_bytree=0.5\n",
        "clf.fit(X_train,\n",
        "        y_train, \n",
        "        verbose=True,\n",
        "        eval_metric = ['merror','mlogloss'],\n",
        "        early_stopping_rounds=12,\n",
        "        eval_set=[(X_test,y_test),(X_train, y_train)])"
      ],
      "metadata": {
        "id": "QM4KQrwt6sJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.best_ntree_limit"
      ],
      "metadata": {
        "id": "t8q9vySb6tbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(clf, open(\"dty_bulk_model.dat\", \"wb\"))"
      ],
      "metadata": {
        "id": "Md4G6mwP6urZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_feature_importance(classifier,X):\n",
        "        # check Important features\n",
        "        feature_importances_df = pd.DataFrame(\n",
        "            {\"feature\": list(X.columns),\n",
        "             \"importance\": classifier.feature_importances_}\n",
        "        ).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "        # Display\n",
        "        print(\"\\n[XGBoostClassifier] feature importance:\")\n",
        "        print(feature_importances_df)"
      ],
      "metadata": {
        "id": "dFTMpr-_6xa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = print_feature_importance(clf, X)\n",
        "print(features)"
      ],
      "metadata": {
        "id": "2188-GSn6yqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test) "
      ],
      "metadata": {
        "id": "aV9EKfqs6z_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions) \n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "gi64fPo-61O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "loaded_model = pickle.load(open(\"dry_bulk_model.dat\", \"rb\"))\n",
        "results = loaded_model.evals_result()\n",
        "epochs = len(results['validation_0']['merror'])\n",
        "x_axis = range(0, epochs)\n",
        "from matplotlib import pyplot\n",
        "fig, ax = pyplot.subplots(figsize=(6,6))\n",
        "ax.plot(x_axis, results['validation_0']['mlogloss'], label='test')\n",
        "ax.plot(x_axis, results['validation_0']['merror'], label='train')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "0P5crVXh62Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "\n",
        "fig, ax = pyplot.subplots()\n",
        "plot_importance(loaded_model, ax=ax)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "0shH7mLh65RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "# import pickle\n",
        "# loaded_model = pickle.load(open(\"lpg_model.dat\", \"rb\"))\n",
        "results = clf.evals_result()\n",
        "pyplot.plot(results['validation_0']['mlogloss'], label='test')\n",
        "pyplot.plot(results['validation_1']['mlogloss'], label='train')\n",
        "pyplot.ylabel(\"Log Loss\")\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "Kg1Ed-qv67jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyplot.plot(results['validation_0']['merror'], label='test')\n",
        "pyplot.plot(results['validation_1']['merror'], label='train')\n",
        "pyplot.ylabel(\"Classification Error\")\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "LaJSfFqF68qv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}