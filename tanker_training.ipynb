{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tanker_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ5kMTHGZGP-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import style\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV,\n",
        "                                     cross_val_score, train_test_split)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "# import category_encoders as ce\n",
        "import time\n",
        "import warnings\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "zIujfjDUZlZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tanker_training_data.csv\", skiprows=0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "khqOrwRTZnLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.arrival_port.value_counts()"
      ],
      "metadata": {
        "id": "qJ4nAITHZoxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sub_segment.value_counts()"
      ],
      "metadata": {
        "id": "4YfEW8K5ZqoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.departure_port.value_counts()"
      ],
      "metadata": {
        "id": "7tb6L9XGdEVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sspd_mstd.value_counts()"
      ],
      "metadata": {
        "id": "J9o4owi4dGHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df).set_title('Distribution of Arrival Ports')"
      ],
      "metadata": {
        "id": "pY_Us5lRdHu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['departure_port','arrival_port']).size()"
      ],
      "metadata": {
        "id": "ZzcpVP40dJf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['departure_port','arrival_port']).size().sort_values(ascending=False)[:12000].sum()/len(df)"
      ],
      "metadata": {
        "id": "Ye5dL041dRVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['departure_port','arrival_port']).size().sort_values(ascending=False)[:12000]"
      ],
      "metadata": {
        "id": "eFwnvhOXdUtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.groupby(['departure_port','arrival_port']).filter(lambda x: len(x) > 4)\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "XuHYEpZ_dqo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df2).set_title('Distribution of Arrival Ports')"
      ],
      "metadata": {
        "id": "c0IyCmkjdvq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.arrival_port.value_counts()"
      ],
      "metadata": {
        "id": "2jGYac9WdyfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.arrival_port.value_counts()[:400].values.sum()/len(df2)"
      ],
      "metadata": {
        "id": "PDrUpYiDd33b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.arrival_port.value_counts()[:400]"
      ],
      "metadata": {
        "id": "WP3OEQnilbCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "removals = df['arrival_port'].value_counts().reset_index()\n",
        "removals = removals[removals['arrival_port'] > 93]['index'].values\n",
        "removals.size\n",
        "df3 = df[df['arrival_port'].isin(removals)]\n",
        "df3.arrival_port.value_counts()\n"
      ],
      "metadata": {
        "id": "D1b-i8f1lbsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "sns.countplot(x=\"arrival_port\", data=df3).set_title('Distribution of Arrival Ports')"
      ],
      "metadata": {
        "id": "2WdIOqsIlixF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.to_csv(r'tanker_trained_data.csv', index = False)"
      ],
      "metadata": {
        "id": "2UBiVsJmd7uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df3.drop('arrival_port',axis=1).copy()\n",
        "X.head()"
      ],
      "metadata": {
        "id": "q4v0oOc_eBls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X.drop(['voyage_id', 'imo','mstd_id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "xsXZOXEkeKhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df3['arrival_port'].copy()\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "MLXfyrYTeMz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded= le.fit(y)\n",
        "filehandler = open(\"enc_targets.obj\",\"wb\")\n",
        "pickle.dump(y_encoded,filehandler)\n",
        "filehandler.close()"
      ],
      "metadata": {
        "id": "XbY0RnGneO7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_changed = y_encoded.transform(y)\n",
        "y_changed"
      ],
      "metadata": {
        "id": "LU7ppnrzeQ25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dp = LabelEncoder()\n",
        "dp_enc = dp.fit(X['departure_port'])\n",
        "filehandler = open(\"dp_enc.obj\",\"wb\")\n",
        "pickle.dump(dp_enc,filehandler)\n",
        "filehandler.close()\n",
        "#########\n",
        "sea = LabelEncoder()\n",
        "sea_enc = sea.fit(X['season'])\n",
        "filehandler = open(\"sea_enc.obj\",\"wb\")\n",
        "pickle.dump(sea_enc,filehandler)\n",
        "filehandler.close()\n",
        "###########\n",
        "seg = LabelEncoder()\n",
        "seg_enc = seg.fit(X['sub_segment'])\n",
        "filehandler = open(\"seg_enc.obj\",\"wb\")\n",
        "pickle.dump(seg_enc,filehandler)\n",
        "filehandler.close()\n",
        "###############\n",
        "sspd = LabelEncoder()\n",
        "sspd_enc = sspd.fit(X['sspd_mstd'])\n",
        "filehandler = open(\"sspd_enc.obj\",\"wb\")\n",
        "pickle.dump(sspd_enc,filehandler)\n",
        "filehandler.close()"
      ],
      "metadata": {
        "id": "BTTC7wJeeSHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"dp_enc.obj\",'rb')\n",
        "dp_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"departure_port\"] = dp_enc.transform(X[\"departure_port\"])\n",
        "############\n",
        "file = open(\"sea_enc.obj\",'rb')\n",
        "sea_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"season\"] = sea_enc.transform(X[\"season\"])\n",
        "##############\n",
        "file = open(\"seg_enc.obj\",'rb')\n",
        "seg_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"sub_segment\"] = seg_enc.transform(X[\"sub_segment\"])\n",
        "#######################\n",
        "file = open(\"sspd_enc.obj\",'rb')\n",
        "sspd_enc = pickle.load(file)\n",
        "file.close()\n",
        "X[\"sspd_mstd\"] = sspd_enc.transform(X[\"sspd_mstd\"])"
      ],
      "metadata": {
        "id": "jpwjkbqMeTnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "Xgrz9oG-eVB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y_changed,test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "L1pnyW86eXbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = xgb.XGBClassifier(objective='multi:softmax',seed=42,learn_rate=0.1,max_depth=6,gamma=0.29,subsample=0.9)#colsample_bytree=0.5\n",
        "clf.fit(X_train,\n",
        "        y_train, \n",
        "        verbose=True,\n",
        "        eval_metric = ['merror','mlogloss'],\n",
        "        early_stopping_rounds=12,\n",
        "        eval_set=[(X_test,y_test),(X_train, y_train)])"
      ],
      "metadata": {
        "id": "6cerpCmTeZQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  clf.best_ntree_limit"
      ],
      "metadata": {
        "id": "KrsYMYoLebbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(clf, open(\"tanker_model.dat\", \"wb\"))"
      ],
      "metadata": {
        "id": "Kk-zmJFheqfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_feature_importance(classifier,X):\n",
        "        # check Important features\n",
        "        feature_importances_df = pd.DataFrame(\n",
        "            {\"feature\": list(X.columns),\n",
        "             \"importance\": classifier.feature_importances_}\n",
        "        ).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "        # Display\n",
        "        print(\"\\n[XGBoostClassifier] feature importance:\")\n",
        "        print(feature_importances_df)"
      ],
      "metadata": {
        "id": "PZBSJsOJeuAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = print_feature_importance(clf, X)\n",
        "print(features)"
      ],
      "metadata": {
        "id": "ZDR7sDYiewIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test) "
      ],
      "metadata": {
        "id": "ydpXuh7hezFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions) \n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "K8JqD-oxe1BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "# import pickle\n",
        "# loaded_model = pickle.load(open(\"lpg_model.dat\", \"rb\"))\n",
        "results = clf.evals_result()\n",
        "pyplot.plot(results['validation_0']['mlogloss'], label='test')\n",
        "pyplot.plot(results['validation_1']['mlogloss'], label='train')\n",
        "pyplot.ylabel(\"Log Loss\")\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "Olpf5tg5e20q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyplot.plot(results['validation_0']['merror'], label='test')\n",
        "pyplot.plot(results['validation_1']['merror'], label='train')\n",
        "pyplot.ylabel(\"Classification Error\")\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "x7WY3KjQfAFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XYGB9A4LjARu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}